from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))
  # Then move kaggle.json into the folder where the API expects to find it.
!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json


!kaggle datasets download -d abdulhasibuddin/malayakew-plant-leaf-dataset


import tensorflow as tf
from zipfile import ZipFile
import os,glob
import cv2
from tqdm._tqdm_notebook import tqdm_notebook as tqdm
import numpy as np
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Convolution2D, Dropout, Dense,MaxPooling2D
from keras.layers import BatchNormalization
from keras.layers import MaxPooling2D
from keras.layers import Flatten


from zipfile import ZipFile
file_name = "/content/malayakew-plant-leaf-dataset.zip"
with ZipFile(file_name,'r') as zip:
  zip.extractall()
  print('Done')


os.chdir('/content/MK/D1/train/Class (26)')
x_train = []
y_train = []
for i in tqdm(os.listdir()):
      img = cv2.imread(i)
      img = cv2.resize(img,(128,128))
      x_train.append(img)
      y_train.append(0)


os.chdir('/content/MK/D1/train/Class (17)')
for i in tqdm(os.listdir()):
      img = cv2.imread(i)
      img = cv2.resize(img,(128,128))
      x_train.append(img)
      y_train.append(1)


os.chdir('/content/MK/D1/train/Class (26)')
x_test = []
y_test = []
for i in tqdm(os.listdir()):
      img = cv2.imread(i)
      img = cv2.resize(img,(128,128))
      x_test.append(img)
      y_test.append(0)

os.chdir('/content/MK/D1/train/Class (17)')
x_test = []
y_test = []
for i in tqdm(os.listdir()):
      img = cv2.imread(i)
      img = cv2.resize(img,(128,128))
      x_test.append(img)
      y_test.append(1)

y_train = np.array(y_train)
X_train = np.array(x_train)
y_test = np.array(y_test)
X_test = np.array(x_test)
print("X_train Shape: ", X_train.shape)
print("X_test Shape: ", X_test.shape)
print("y_train Shape: ", y_train.shape)
print("y_test Shape: ", y_test.shape)

from keras.preprocessing.image import ImageDataGenerator
datagen = ImageDataGenerator(
    rotation_range=30,      
    width_shift_range=0.3,  
    height_shift_range=0.2, 
    shear_range=0.2,        
    zoom_range=0.4,           
    fill_mode='nearest'    
)

train_generator = datagen.flow(X_train, y_train,batch_size=32)
steps_per_epoch = len(train_generator)  # Calculate steps per epoch
for i in range(steps_per_epoch):
    X_train_aug, y_train_aug = train_generator.next()
X_train = np.concatenate((X_train,X_train_aug))
y_train = np.concatenate((y_train,y_train_aug))

print("X_train shape: ", X_train.shape)
print("y_train shape: ", y_train.shape)

from keras.applications import vgg16


img_rows, img_cols = 128, 128


vgg = vgg16.VGG16(weights = 'imagenet',
                 include_top = False,
                 input_shape = (img_rows, img_cols, 3))

for layer in vgg.layers:
    layer.trainable = False

for (i,layer) in enumerate(vgg.layers):
    print(str(i) + " "+ layer.__class__.__name__, layer.trainable)

from keras import regularizers
def lw(bottom_model, num_classes):
    """creates the top or head of the model that will be
    placed ontop of the bottom layers"""

    top_model = bottom_model.output
    top_model = GlobalAveragePooling2D()(top_model)
    top_model = Dense(1024,activation='relu',kernel_regularizer=regularizers.l2(0.0001))(top_model)
    top_model = Dropout(0.2)(top_model)
    top_model = Dense(1024,activation='relu',kernel_regularizer=regularizers.l2(0.0001))(top_model)
    top_model = Dropout(0.5)(top_model)
    top_model = Dense(512,activation='relu',kernel_regularizer=regularizers.l2(0.0001))(top_model)
    top_model = Dropout(0.3)(top_model)
    top_model = Dense(num_classes,activation='sigmoid')(top_model)
    return top_model

from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D
from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D

from keras.models import Model


num_classes = 1

FC_Head = lw(vgg, num_classes)

model = Model(inputs = vgg.input, outputs = FC_Head)
print(model.summary())

from tensorflow.keras.models import Model
import tensorflow as tf
from tensorflow.keras import backend as K
metrics = [
        'accuracy',
        tf.keras.metrics.AUC(),
        tf.keras.metrics.Recall(),
        tf.keras.metrics.Precision(),
        tf.keras.metrics.SpecificityAtSensitivity(0.5),
        tf.keras.metrics.SensitivityAtSpecificity(0.5),
        tf.keras.metrics.FalseNegatives(),
        tf.keras.metrics.FalsePositives(),
        tf.keras.metrics.TrueNegatives(),
        tf.keras.metrics.TruePositives(),]
model.compile(optimizer='adam',loss='binary_crossentropy',metrics=metrics)

callbacks = [
    tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',patience=4
    )
]
history = model.fit(X_train, y_train, epochs=5,batch_size=32,validation_split=0.3,callbacks=callbacks, shuffle= True)

%matplotlib inline
import matplotlib.pyplot as plt
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Training accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend(loc=0)
plt.figure()

plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()
